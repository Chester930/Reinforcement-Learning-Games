<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>強化學習訓練分析報告</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f8f9fa;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 960px;
            margin: auto;
            background: #fff;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #0056b3;
            border-bottom: 2px solid #e9ecef;
            padding-bottom: 10px;
            margin-top: 30px;
        }
        h1 {
            text-align: center;
            color: #004085;
            font-size: 2.5em;
        }
        .section {
            margin-bottom: 30px;
        }
        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        .summary-card {
            background: #e9f5ff;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            border-left: 5px solid #007bff;
        }
        .summary-card .label {
            font-size: 0.9em;
            color: #555;
        }
        .summary-card .value {
            font-size: 1.8em;
            font-weight: bold;
            color: #0056b3;
        }
        .value.trend-up {
            color: #28a745;
        }
        .value.trend-down {
            color: #dc3545;
        }
        ul {
            list-style-type: none;
            padding-left: 0;
        }
        li {
            background: #f8f9fa;
            border: 1px solid #ddd;
            padding: 15px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        strong {
            color: #0056b3;
        }
        .problem {
            border-left: 5px solid #dc3545;
            background-color: #fbeeed;
            padding: 15px;
            margin-top: 15px;
            border-radius: 5px;
        }
        .recommendation {
            border-left: 5px solid #28a745;
            background-color: #eaf7ec;
            padding: 15px;
            margin-top: 15px;
            border-radius: 5px;
        }
        .final-score {
            text-align: center;
            font-size: 3em;
            font-weight: bold;
            color: #007bff;
            margin: 20px 0;
        }
        .score-desc {
            text-align: center;
            color: #6c757d;
            margin-bottom: 30px;
        }
        code {
            background-color: #e9ecef;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }
        th, td {
            padding: 12px;
            border: 1px solid #dee2e6;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
            color: #0056b3;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>強化學習訓練分析報告</h1>

        <div class="section" id="evaluation">
            <h2>1. 學習效果評估</h2>
            <h3>總體評價</h3>
            <p>AI代理（Agent）在訓練過程中表現出<strong>顯著且快速的學習能力</strong>。從學習曲線來看，代理成功地從早期頻繁失敗的探索階段，迅速過渡到能夠穩定獲得高獎勵的策略利用階段。最終性能指標（最終獎勵1000，最終步數100）表明代理已學會如何在環境中最大化累積獎勵。</p>
            
            <h3>學習曲線分析</h3>
            <div style="width:100%; margin: 20px 0;">
                <canvas id="learningCurveChart"></canvas>
            </div>
            <ul>
                <li><strong>獎勵趨勢 (Reward Trend)</strong>: 獎勵曲線呈現典型的S型增長。初期 (1-5回合) 獎勵值低且波動劇烈，反映隨機探索；中期 (6-15回合) 獎勵值快速爬升，顯示策略開始生效；後期 (16-100回合) 獎勵值穩定在高水平，策略基本收斂。</li>
                <li><strong>步數趨勢 (Step Trend)</strong>: 步數曲線與獎勵曲線高度相關。代理在學會有效策略後，能夠在環境中存活更長時間，最終穩定地達到單回合最大步數（100步）。這意味著代理成功學會了<strong>如何避免任務終止的負面狀態</strong>。</li>
            </ul>

            <h3>收斂性與最終性能</h3>
            <p><strong>收斂判斷</strong>: 從趨勢上看，訓練在100回合內<strong>已基本收斂</strong>到一個穩定的策略。後期的獎勵和步數波動性很小。</p>
            <p><strong>最終性能</strong>: 代理達到了單回合1000的獎勵和100步的時長，這可能是環境設定的上限。從最大化累積獎勵的目標來看，<strong>最終性能表現優異</strong>。</p>
        </div>

        <div class="section" id="diagnosis">
            <h2>2. 問題診斷</h2>
            <p>儘管學習效果顯著，但深入分析Q-Table和最優路徑後，發現存在一個<strong>關鍵且隱蔽的問題</strong>。</p>
            <div class="problem">
                <h3>主要問題：策略振盪與次優局部最優解 (Suboptimal Oscillation)</h3>
                <p><strong>最優路徑分析</strong>: 報告的最優路徑為 <code>[(4, 4), (5, 4), (5, 5), (5, 4)]</code>。這條路徑包含了一個<strong>死循環</strong>: <code>(5, 4) -> (5, 5) -> (5, 4)</code>。</p>
                <p><strong>問題根源</strong>:</p>
                <ol>
                    <li><strong>Q-Table 證據</strong>: <code>Q((5,4), right)</code> ≈ <code>Q((5,5), left)</code> ≈ <code>98.99</code>。這兩個狀態-動作對的Q值極其接近且是各自狀態下的最優選擇，從而導致代理在這兩個高價值狀態之間來回振盪。</li>
                    <li><strong>獎勵函數陷阱 (Reward Hacking)</strong>: 代理似乎發現了一個「獎勵農場」。它沒有去尋找最終的目標狀態，而是選擇在一個安全的、可以持續獲得步數獎勵的區域內徘徊。</li>
                </ol>
                <p><strong>結論</strong>: 代理學到的並非是「完成任務」的最優策略，而是「在規則內最大化得分」的次優策略。</p>
            </div>
        </div>

        <div class="section" id="recommendations">
            <h2>3. 改進建議</h2>
            <p>針對上述診斷，提出以下具體改進建議：</p>
            <div class="recommendation">
                <h3>1. 獎勵函數工程 (Reward Function Engineering) - <strong>最高優先級</strong></h3>
                <ul>
                    <li><strong>增加終點獎勵</strong>: 為到達最終目標狀態設置一個遠大於步數累積獎勵的巨大正獎勵（如 <code>+5000</code>）。</li>
                    <li><strong>增加步數懲罰</strong>: 將每一步的獎勵從正值改為一個小的負值（如 <code>-0.1</code>），以激勵代理尋找最短路徑。</li>
                </ul>
            </div>
            <div class="recommendation">
                <h3>2. 調整超參數 (Hyperparameter Tuning)</h3>
                <ul>
                    <li><strong>探索率 (Epsilon)</strong>: 減緩衰減速度，並設置一個最小探索率（如 <code>0.01</code>）以避免完全停止探索。</li>
                    <li><strong>折扣因子 (Gamma)</strong>: 適當降低 Gamma（如 <code>0.9</code>），讓代理更關注於能快速獲得的終點獎勵。</li>
                </ul>
            </div>
            <div class="recommendation">
                <h3>3. 訓練策略優化</h3>
                <p>將訓練回合數增加到 <strong>500 至 2000 回合</strong>，給予代理更充分的時間進行探索和收斂。</p>
            </div>
        </div>

        <div class="section" id="algorithm">
            <h2>4. 算法特性分析</h2>
            <p>根據數據推斷，當前使用的是<strong>經典的表格型Q-Learning算法</strong>。</p>
            <table>
                <thead>
                    <tr>
                        <th>特性</th>
                        <th>分析</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>優點</strong></td>
                        <td>原理簡單、可解釋性強、理論上保證收斂。</td>
                    </tr>
                    <tr>
                        <td><strong>缺點</strong></td>
                        <td>僅適用於離散且有限的狀態/動作空間（維度詛咒），樣本效率低。</td>
                    </tr>
                    <tr>
                        <td><strong>適用場景</strong></td>
                        <td>對於當前的網格世界(Grid World)問題非常合適。問題的關鍵在於獎勵函數設計，而非算法選擇。</td>
                    </tr>
                    <tr>
                        <td><strong>替代方案</strong></td>
                        <td>SARSA (更保守的策略), DQN (適用於大規模、連續狀態空間)。</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section" id="summary">
            <h2>5. 總結與評分</h2>
            <div class="final-score">7.5 / 10</div>
            <p class="score-desc">代理學習能力強，但最終策略存在致命缺陷。</p>
            <div class="summary-grid">
                <div class="summary-card">
                    <div class="label">主要成就</div>
                    <div class="value">學會避免懲罰並長期存活</div>
                </div>
                <div class="summary-card" style="border-color: #dc3545;">
                    <div class="label">核心問題</div>
                    <div class="value" style="color: #dc3545;">陷入局部最優的「刷分」循環</div>
                </div>
                <div class="summary-card" style="border-color: #ffc107;">
                    <div class="label">實用性評估</div>
                    <div class="value" style="color: #b98900;">當前不可用，改進後潛力高</div>
                </div>
            </div>
        </div>
    </div>

    <script>
        const rewardData = [-52, 176, -43, 292, 135, 461, 376, 450, 438, 560, 101, 615, 615, 127, 424, 593, 681, 758, 780, 846];
        const stepData = [3, 39, 5, 77, 47, 100, 81, 100, 85, 100, 37, 100, 100, 33, 77, 100, 100, 100, 100, 100];
        const labels = Array.from({ length: 20 }, (_, i) => `回合 ${i + 1}`);

        const ctx = document.getElementById('learningCurveChart').getContext('2d');
        const learningCurveChart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: labels,
                datasets: [{
                    label: '每回合獎勵',
                    data: rewardData,
                    borderColor: 'rgb(0, 123, 255)',
                    backgroundColor: 'rgba(0, 123, 255, 0.1)',
                    yAxisID: 'y-reward',
                    tension: 0.1
                }, {
                    label: '每回合步數',
                    data: stepData,
                    borderColor: 'rgb(40, 167, 69)',
                    backgroundColor: 'rgba(40, 167, 69, 0.1)',
                    yAxisID: 'y-steps',
                    tension: 0.1
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: true,
                plugins: {
                    title: {
                        display: true,
                        text: '學習曲線 (前20回合)',
                        font: {
                            size: 18
                        }
                    }
                },
                scales: {
                    x: {
                        title: {
                            display: true,
                            text: '訓練回合'
                        }
                    },
                    'y-reward': {
                        type: 'linear',
                        position: 'left',
                        title: {
                            display: true,
                            text: '獎勵值'
                        },
                        grid: {
                            drawOnChartArea: false, 
                        },
                    },
                    'y-steps': {
                        type: 'linear',
                        position: 'right',
                        title: {
                            display: true,
                            text: '步數'
                        }
                    }
                }
            }
        });
    </script>
</body>
</html>