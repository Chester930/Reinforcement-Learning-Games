<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>強化學習訓練分析報告</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {
            --primary-color: #007bff;
            --secondary-color: #6c757d;
            --success-color: #28a745;
            --warning-color: #ffc107;
            --danger-color: #dc3545;
            --light-color: #f8f9fa;
            --dark-color: #343a40;
            --font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --border-radius: 0.3rem;
        }
        body {
            font-family: var(--font-family);
            line-height: 1.6;
            color: var(--dark-color);
            background-color: #f4f7f9;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: #fff;
            padding: 2rem;
            border-radius: var(--border-radius);
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        header {
            text-align: center;
            margin-bottom: 2rem;
            border-bottom: 2px solid var(--primary-color);
            padding-bottom: 1rem;
        }
        header h1 {
            color: var(--primary-color);
            margin: 0;
        }
        header p {
            color: var(--secondary-color);
            margin-top: 0.5rem;
        }
        h2 {
            color: var(--primary-color);
            border-bottom: 1px solid #e0e0e0;
            padding-bottom: 0.5rem;
            margin-top: 2rem;
        }
        h3 {
            color: #333;
            margin-top: 1.5rem;
        }
        .section {
            margin-bottom: 2rem;
        }
        .summary-card {
            background: var(--light-color);
            border: 1px solid #dee2e6;
            border-left: 5px solid var(--primary-color);
            padding: 1.5rem;
            border-radius: var(--border-radius);
            margin-bottom: 2rem;
        }
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin-top: 1rem;
        }
        .card {
            background: #fff;
            padding: 1.5rem;
            border-radius: var(--border-radius);
            box-shadow: 0 2px 6px rgba(0,0,0,0.08);
            border: 1px solid #e9ecef;
        }
        .card h4 {
            margin-top: 0;
            color: var(--primary-color);
        }
        .tag {
            display: inline-block;
            padding: 0.25em 0.6em;
            font-size: 75%;
            font-weight: 700;
            line-height: 1;
            text-align: center;
            white-space: nowrap;
            vertical-align: baseline;
            border-radius: 0.25rem;
            color: #fff;
        }
        .tag-success { background-color: var(--success-color); }
        .tag-warning { background-color: var(--warning-color); color: #212529; }
        .tag-danger { background-color: var(--danger-color); }
        .score-circle {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: var(--warning-color);
            color: var(--dark-color);
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 2.5rem;
            font-weight: bold;
            margin: 1rem auto;
            border: 5px solid #e6a000;
        }
        ul {
            padding-left: 20px;
        }
        li {
            margin-bottom: 0.5rem;
        }
        code {
            background-color: #e9ecef;
            padding: 0.2em 0.4em;
            margin: 0;
            font-size: 85%;
            border-radius: 3px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 1rem;
        }
        th, td {
            padding: 0.75rem;
            text-align: left;
            border-bottom: 1px solid #dee2e6;
        }
        th {
            background-color: var(--light-color);
        }
        @media (max-width: 768px) {
            body { padding: 10px; }
            .container { padding: 1rem; }
            .grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>強化學習訓練分析報告</h1>
            <p><strong>分析對象:</strong> 基於Q-Table的強化學習智能體訓練過程 | <strong>報告日期:</strong> 2023年10月27日</p>
        </header>

        <section class="summary-card section">
            <h3>總體摘要</h3>
            <p>
                本次訓練共進行了100個回合，智能體在學習過程中表現出明顯的進步趨勢，成功定位到了一個高獎勵值的區域。然而，深入分析顯示，智能體
                <strong>未能學會達成最終目標的最優策略</strong>，而是陷入了一個高獎勵的
                <strong>局部最優解（循環陷阱）</strong>中，導致回合無法正常終止。儘管獎勵值較高，但目前的模型不具備實用性，需要進一步的調整與優化。
            </p>
        </section>

        <section id="evaluation" class="section">
            <h2>1. 學習效果評估</h2>
            <div class="grid">
                <div class="card">
                    <h4>學習曲線分析</h4>
                    <p><strong>獎勵趨勢:</strong> <span class="tag tag-success">正面 ✅</span> <br> 總體上升，平均獎勵`832.57`，表明智能體能找到高獎勵狀態。</p>
                    <p><strong>步數趨勢:</strong> <span class="tag tag-warning">警告 ⚠️</span> <br> 最終步數`100`，可能達到上限，意味著任務未完成（超時）。</p>
                    <p><strong>初期波動:</strong> 正常的探索行為，反映了較高的探索率設置。</p>
                </div>
                <div class="card">
                    <h4>策略與收斂性</h4>
                    <p><strong>策略有效性:</strong> <span class="tag tag-danger">負面 ❌</span> <br> 策略無效。智能體陷入 `(5,4) <=> (5,3)` 的循環，無法完成任務。</p>
                    <p><strong>收斂狀態:</strong> <span class="tag tag-danger">未收斂 ❌</span> <br> 未收斂至最優策略，而是收斂到了次優的循環策略中。</p>
                </div>
            </div>
            <div class="card" style="margin-top: 1.5rem;">
                <h4>獎勵與步數學習曲線 (前20回合)</h4>
                <canvas id="learningCurveChart"></canvas>
            </div>
        </section>

        <section id="diagnosis" class="section">
            <h2>2. 問題診斷</h2>
            <ul>
                <li><strong>核心問題 - 循環陷阱 (Looping):</strong> 這是最嚴重的問題。智能體在狀態 <code>(5,4)</code> 和 <code>(5,3)</code> 之間無限循環，因為這兩個動作的Q值最高且幾乎相等，導致貪婪策略失效。</li>
                <li><strong>探索不足或利用過早:</strong> 在訓練後期，探索率可能過低，導致智能體無法跳出已發現的局部最優解。</li>
                <li><strong>獎勵函數設計缺陷:</strong> 當前的獎勵機制可能未能有效區分“停留在好位置”和“到達終點”的價值，且缺乏對低效率（步數過多）的懲罰。</li>
                <li><strong>Q-Table質量:</strong> 儘管成功標識了高價值區域，但Q值的微小差異導致了不穩定的循環行為。</li>
            </ul>
        </section>

        <section id="suggestions" class="section">
            <h2>3. 改進建議</h2>
            <div class="grid">
                <div class="card">
                    <h4>💡 參數調整</h4>
                    <ul>
                        <li><strong>探索率(ε):</strong> 使用更緩慢的衰減策略，並設置一個最小探索率（如`0.1`），保證後期探索。</li>
                        <li><strong>學習率(α):</strong> 嘗試降低並使其衰減，以穩定Q值收斂。</li>
                        <li><strong>折扣因子(γ):</strong> 當前值可能合適，但可作為次要調整項。</li>
                    </ul>
                </div>
                <div class="card">
                    <h4>🚀 策略與環境優化</h4>
                    <ul>
                        <li><strong>引入步數懲罰 (核心建議):</strong> 為每一步增加小的負獎勵 (e.g., `-0.1`)，激勵智能體尋找最短路徑。</li>
                        <li><strong>加大終點獎勵:</strong> 顯著拉開終點獎勵與中間狀態獎勵的差距。</li>
                        <li><strong>增加訓練回合:</strong> 建議增加到 1000-5000 回合以上。</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="algorithm" class="section">
            <h2>4. 算法特性分析 (Q-Learning)</h2>
            <div class="grid">
                <div class="card">
                    <h4>優點</h4>
                    <ul>
                        <li>實現簡單</li>
                        <li>離策略(Off-Policy)，學習效率高</li>
                        <li>非常適合小型、離散的環境</li>
                    </ul>
                </div>
                <div class="card">
                    <h4>缺點</h4>
                    <ul>
                        <li>易陷入局部最優</li>
                        <li>收斂速度可能較慢</li>
                        <li>不適用於大型狀態空間（維度災難）</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="summary" class="section">
            <h2>5. 總結與評分</h2>
            <div style="text-align:center;">
                 <h3>整體訓練效果評分</h3>
                 <div class="score-circle">4/10</div>
            </div>
            <div class="grid">
                <div class="card">
                    <h4>✅ 主要成就</h4>
                    <ul>
                        <li>成功定位了環境中的高價值區域。</li>
                        <li>驗證了Q-Learning算法在該環境下的基本學習能力。</li>
                    </ul>
                </div>
                <div class="card">
                    <h4>❌ 主要問題</h4>
                    <ul>
                        <li>策略循環，陷入局部最優。</li>
                        <li>因循環導致效率極低（步數超時）。</li>
                        <li>潛在的獎勵函數設計缺陷。</li>
                    </ul>
                </div>
            </div>
             <div class="summary-card" style="margin-top: 2rem; border-left-color: var(--danger-color);">
                <h4>實用性評估</h4>
                <p><strong>當前狀態: 無實用性。</strong> 一個無法穩定完成任務的智能體是不可部署的。</p>
                <p><strong>改進後潛力: 高。</strong> 該問題是強化學習中的典型挑戰，通過實施改進建議（特別是增加步數懲罰和優化探索策略），模型有極大可能被訓練成一個高效、可靠的最優模型。</p>
            </div>
        </section>

    </div>

    <script>
        const rewardData = [44, 123, 208, 111, -3, 472, 472, -32, -52, 90, 405, 626, 791, 615, 549, 571, 725, 857, 184, 714];
        const stepData = [39, 37, 73, 49, 9, 100, 100, 5, 3, 37, 85, 100, 100, 100, 100, 100, 100, 100, 31, 100];
        const labels = Array.from({ length: 20 }, (_, i) => `回合 ${i + 1}`);

        const ctx = document.getElementById('learningCurveChart').getContext('2d');
        const learningCurveChart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: labels,
                datasets: [
                    {
                        label: '每回合獎勵',
                        data: rewardData,
                        borderColor: 'rgba(0, 123, 255, 1)',
                        backgroundColor: 'rgba(0, 123, 255, 0.1)',
                        yAxisID: 'y',
                        tension: 0.1,
                        fill: true,
                    },
                    {
                        label: '每回合步數',
                        data: stepData,
                        borderColor: 'rgba(255, 193, 7, 1)',
                        backgroundColor: 'rgba(255, 193, 7, 0.1)',
                        yAxisID: 'y1',
                        tension: 0.1,
                        fill: false,
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                interaction: {
                    mode: 'index',
                    intersect: false,
                },
                stacked: false,
                plugins: {
                    title: {
                        display: true,
                        text: '獎勵與步數變化趨勢'
                    }
                },
                scales: {
                    y: {
                        type: 'linear',
                        display: true,
                        position: 'left',
                        title: {
                            display: true,
                            text: '獎勵值'
                        }
                    },
                    y1: {
                        type: 'linear',
                        display: true,
                        position: 'right',
                        title: {
                            display: true,
                            text: '步數'
                        },
                        grid: {
                            drawOnChartArea: false, // only want the grid lines for one axis to show up
                        },
                    },
                }
            }
        });
    </script>
</body>
</html>